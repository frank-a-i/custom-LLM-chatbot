{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "To demonstrate that the estimation performance of a large language model can be greatly improved without any further training, this notebook takes an older model from OpenAI and data that is not likely available in its training. Eventually the inference of the vanilla modus and the enhanced version are compared. In order to avoid that the data is present in the model's training data, a relatively new and non-popular topic is chosen.\n",
    "\n",
    "The data will be about Zynthian user guides. Zynthian (https://zynthian.org/) is a young open source project that turns a Raspberry Pi into a synthesizer instrument.\n",
    "\n",
    "The Zynthian user guide data is shared as creative commons license CC BY-SA 3.0 and so is this code \n",
    "\n",
    "[![Creative Commons](https://wiki.zynthian.org/resources/assets/licenses/cc-by-sa.png)](https://creativecommons.org/licenses/by-sa/3.0/)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "First the Zynthian focused information need to get downloaded, cleaned and prepared so that they eventually can get ranked and sorted by relevance of arbitrary questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e3e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d397132",
   "metadata": {},
   "source": [
    "Define notebook wide common settings for interacting with OpenAI's model.\n",
    "\n",
    "__Important Note__: please add your API key to the \"open_ai_key.txt\" file or assign it directly to the `openai.api_key` parameter below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "embedding_model_name = \"text-embedding-ada-002\"\n",
    "completion_model_name = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "\n",
    "with open(\"open_ai_key.txt\", \"r\") as keyfile:\n",
    "    key_str = keyfile.read().replace(\"\\n\", \"\")\n",
    "    assert len(key_str) > 0, \"Can't continue without specifying a API key for OpenAI\"\n",
    "openai.api_key = key_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23811553",
   "metadata": {},
   "source": [
    "### Get the raw context data\n",
    "\n",
    "Zynthian offers a Wiki where the user guides can be fetched from. This HTML data needs to be converted into human readable strings, and cleaned from dublicates or even empty entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22844f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V5 |V4 |Touch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zynthian Oram is the most recent version of zy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is strongly recommended that you read secti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This guide is a living document, subject to fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The fundamental building block of zynthian's s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>NOTE: Remember to put PAD CONTROLS in CC mode....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>In this mode, all notes of the KeyBed are used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>For other settings, you can use the Knobs. Mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>It works much like the Launchpad Mini MK3.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>This Korg nanoKONTROL2 driver maps the mixer s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0                                        V5 |V4 |Touch\n",
       "1    Zynthian Oram is the most recent version of zy...\n",
       "2    It is strongly recommended that you read secti...\n",
       "3    This guide is a living document, subject to fr...\n",
       "4    The fundamental building block of zynthian's s...\n",
       "..                                                 ...\n",
       "482  NOTE: Remember to put PAD CONTROLS in CC mode....\n",
       "483  In this mode, all notes of the KeyBed are used...\n",
       "484  For other settings, you can use the Knobs. Mov...\n",
       "488         It works much like the Launchpad Mini MK3.\n",
       "497  This Korg nanoKONTROL2 driver maps the mixer s...\n",
       "\n",
       "[386 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_zynthian_context() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function provides essential Zynthian user guide information, \n",
    "    extracted from all <p></p> sections of its Wiki.\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "    Returns:\n",
    "        pd.DataFrame: cleaned DataFrame with the extracted data in the \"text\" column name\n",
    "    \"\"\"\n",
    "    \n",
    "    # define set of webpages with user guides\n",
    "    landing_page = \"https://wiki.zynthian.org/index.php\"\n",
    "    user_guide_pages =[\n",
    "        \"Zynthian_UI_User%27s_Guide_-_Oram\",\n",
    "        \"ZynSeq_User_Guide\",\n",
    "        \"ZynSampler_User_Guide\",\n",
    "        \"Web_Configuration_User_Guide\",\n",
    "        \"Supported_plug_%26_play_MIDI_controllers\",\n",
    "    ]\n",
    "\n",
    "    # download & extract information from said web pages\n",
    "    all_paragraphs = list()\n",
    "    for user_guide_page in user_guide_pages:\n",
    "        subpage_response = requests.get(os.path.join(landing_page, user_guide_page))\n",
    "        soup = BeautifulSoup(subpage_response.text)\n",
    "        user_guide_p = soup.find_all(\"p\")    \n",
    "\n",
    "        for cur_p in user_guide_p:\n",
    "            all_paragraphs.append(cur_p.text.replace(\"\\n\", \"\"))\n",
    "\n",
    "\n",
    "    # turn it to a dataframe and apply data cleaning\n",
    "    df = pd.DataFrame()\n",
    "    df[\"text\"] = all_paragraphs\n",
    "    df = df[df[\"text\"] != \"\"]\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    return df\n",
    "    \n",
    "context_df = extract_zynthian_context()\n",
    "context_df  # let's peek into the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Query Completion\n",
    "\n",
    "In this section the mechanisms are prepared in order to provide a prompt with a meaningful context, where the LLM can extract valuable information for the given user question.\n",
    "\n",
    "### Calculating Embeddings\n",
    "\n",
    "Embeddings are necessary for model inference but we're also using it to compare the similarity of a given user-question with the Zynthian user-guides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d04eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V5 |V4 |Touch</td>\n",
       "      <td>[-0.009096662513911724, -0.007616293150931597,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zynthian Oram is the most recent version of zy...</td>\n",
       "      <td>[-0.029481329023838043, -0.016066910699009895,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is strongly recommended that you read secti...</td>\n",
       "      <td>[-0.010694820433855057, 0.010080959647893906, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This guide is a living document, subject to fr...</td>\n",
       "      <td>[-0.0006172802532091737, -0.000813496182672679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The fundamental building block of zynthian's s...</td>\n",
       "      <td>[-0.008502153679728508, -0.005421128589659929,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>NOTE: Remember to put PAD CONTROLS in CC mode....</td>\n",
       "      <td>[-0.020462140440940857, -0.013787965290248394,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>In this mode, all notes of the KeyBed are used...</td>\n",
       "      <td>[-0.01658054068684578, 0.002622124506160617, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>For other settings, you can use the Knobs. Mov...</td>\n",
       "      <td>[0.009522629901766777, -0.01551835983991623, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>It works much like the Launchpad Mini MK3.</td>\n",
       "      <td>[-0.009409577585756779, 0.012401715852320194, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>This Korg nanoKONTROL2 driver maps the mixer s...</td>\n",
       "      <td>[-0.002310585929080844, -0.022910218685865402,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0                                        V5 |V4 |Touch   \n",
       "1    Zynthian Oram is the most recent version of zy...   \n",
       "2    It is strongly recommended that you read secti...   \n",
       "3    This guide is a living document, subject to fr...   \n",
       "4    The fundamental building block of zynthian's s...   \n",
       "..                                                 ...   \n",
       "482  NOTE: Remember to put PAD CONTROLS in CC mode....   \n",
       "483  In this mode, all notes of the KeyBed are used...   \n",
       "484  For other settings, you can use the Knobs. Mov...   \n",
       "488         It works much like the Launchpad Mini MK3.   \n",
       "497  This Korg nanoKONTROL2 driver maps the mixer s...   \n",
       "\n",
       "                                            embeddings  \n",
       "0    [-0.009096662513911724, -0.007616293150931597,...  \n",
       "1    [-0.029481329023838043, -0.016066910699009895,...  \n",
       "2    [-0.010694820433855057, 0.010080959647893906, ...  \n",
       "3    [-0.0006172802532091737, -0.000813496182672679...  \n",
       "4    [-0.008502153679728508, -0.005421128589659929,...  \n",
       "..                                                 ...  \n",
       "482  [-0.020462140440940857, -0.013787965290248394,...  \n",
       "483  [-0.01658054068684578, 0.002622124506160617, 0...  \n",
       "484  [0.009522629901766777, -0.01551835983991623, -...  \n",
       "488  [-0.009409577585756779, 0.012401715852320194, ...  \n",
       "497  [-0.002310585929080844, -0.022910218685865402,...  \n",
       "\n",
       "[386 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def attach_embeddings(df: pd.DataFrame, embedding_model_name:str, batch_size=100) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes a DataFrame with raw context information and calculates its embeddings and returns the updated frame.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with human readable strings in column \"text\" that should be encoded\n",
    "        embedding_model_name: in what manner OpenAI should encode the data\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with \"text\" and \"embedding\" columns\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings = []\n",
    "    batch_size = 100  # iterate batch-wise to avoid API-overstraining\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        # Actual embeddings will be calculated by OpenAI and applied for via its API\n",
    "        response = openai.Embedding.create(\n",
    "            input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n",
    "            engine=embedding_model_name\n",
    "        )\n",
    "\n",
    "        # Turn OpenAI packet into a list of embeddings\n",
    "        embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "    df[\"embeddings\"] = embeddings\n",
    "    return df\n",
    "\n",
    "context_with_embeddings_df = attach_embeddings(context_df, embedding_model_name)\n",
    "context_with_embeddings_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce287761",
   "metadata": {},
   "source": [
    "### Prepare temporary context\n",
    "\n",
    "The user guide information was downloaded and stored in an arbitrary fashion. OpenAI's model interface is limited by the total number of tokens in a prompt. It's because of this we can't use the full extracted information and have to prepare a subset of most relevant information. This can be achieved by encoding embeddings of the context paragarphs and measure its likeliness to the encoded question like in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a82a45a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is known about tempo?\n",
      "\n",
      "[info] Unorderd DataFrame\n",
      "0                                        V5 |V4 |Touch\n",
      "1    Zynthian Oram is the most recent version of zy...\n",
      "2    It is strongly recommended that you read secti...\n",
      "Name: text, dtype: object\n",
      "\n",
      "[info] DataFrame ordered by relevance\n",
      "265    The current tempo is saved and loaded with eac...\n",
      "264    Tempo is the rate at which the sequencer plays...\n",
      "240    Tempo may be adjusted using the SNAPSHOT encod...\n",
      "Name: text, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_context(question:str, df:pd.DataFrame, embedding_model_name:str, metric:str=\"cosine\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes the unordered context data and orders it by relevance \n",
    "    according to the given question.\n",
    "    \n",
    "    Args:\n",
    "        question: the string that is used to order the dataset by likeliness\n",
    "        df: the unordered DataFrame with \"text\" and \"embeddings\" columns\n",
    "        embedding_model_name: in what manner OpenAI should encode the data\n",
    "    Returns:\n",
    "        pd.DataFrame: a DataFrame sorted by relevance to the given question\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Call OpenAI's API to calculate the relevance parameter and attach it to the dataframe\n",
    "    df[\"distances\"] = distances_from_embeddings(\n",
    "        query_embedding=get_embedding(question, engine=embedding_model_name),\n",
    "        embeddings=df[\"embeddings\"].values,\n",
    "        distance_metric=metric\n",
    "    )\n",
    "    \n",
    "    # Take the unordered DataFrame and sort it by the just calculcated relevance parameter\n",
    "    return df.sort_values(\"distances\", ascending=True)\n",
    "\n",
    "test_question = \"What is known about tempo?\"\n",
    "relevant_context = get_relevant_context(test_question, context_with_embeddings_df, embedding_model_name)\n",
    "\n",
    "n_check_entries = 3\n",
    "print(f\"Q: {test_question}\\n\")\n",
    "print(f\"[info] Unorderd DataFrame\\n{context_with_embeddings_df[0:n_check_entries]['text']}\\n\")\n",
    "print(f\"[info] DataFrame ordered by relevance\\n{relevant_context[0:n_check_entries]['text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bac9ab",
   "metadata": {},
   "source": [
    "## Prompt generator\n",
    "\n",
    "In order that we can use the chat bot with the extended context information, a standardized way of creating its prompt is being prepared here. It carefully watches the number of utilized token doesn't exceed its limits, puts the relevant context and eventually the actual query into one large string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582f0656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Making a prompt for: What is known about tempo?\n",
      "[info] Limited context to 30/386 paragraphs\n",
      "[info] Created following prompt:\n",
      "===========================\n",
      "\n",
      "Context:\n",
      "The current tempo is saved and loaded with each snapshot.\n",
      "---\n",
      "Tempo is the rate at which the sequencer plays back notes measured in beats per minutes (BPM). By default ZynSeq plays sequences at 120 BPM. Adjust Tempo with the SNAPSHOT encoder. The tempo is briefly displayed in the title bar. There is also a menu option to adjust tempo.\n",
      "---\n",
      "Tempo may be adjusted using the SNAPSHOT encoder or by selecting \"Tempo\" from the menu.\n",
      "---\n",
      "ZynSeq allows tempo to be adjusted from 1.0 BPM to 420.0 BPM in 0.1 BPM steps. Tempo may also be altered by external modules, e.g. MIDI player.\n",
      "---\n",
      "Knob K3 is used to adjust the tempo. When rotated, the Zynthian tempo screen will be shown briefly. This tempo setting is synchronized with the MPK. \n",
      "---\n",
      "For instance, if you are in the mixer view and short-push OPT/ADMIN, the Main menu will be opened. If you short-push it again, the Admin menu will be opened. Then, if you bold-push the MIX/LEVEL button, the Audio Levels view will be opened. You push \"metronome\" button and the Tempo settings view will be opened. If you tap-it several times, the tempo BPM will be changed, e.g. tap twice per second to set tempo to 120BPM.\n",
      "---\n",
      "Each sequence has a timebase track which may have tempo and time signature (beats per bar) events. These will influence all playback. The ability to manipulate sequence timebase events is not yet implemented.\n",
      "---\n",
      "View buttons are outlined on green in the image and they allow direct access to the main views. Most of these buttons have 2 different views assigned, with a horizontal line separating two printed labels. The primary view is printed at top and the secondary view is printed at bottom. The \"metronome\" button is the exception, as it's the tap-tempo button. You push it once to access the tempo settings view, but you can tap-it several times to change the tempo BPM. Try it!\n",
      "---\n",
      "Sequences may be configured to stay synchronised with shorter phrases pausing and starting again at start of bar or polymeters may be implemented with shorter patterns driftting across longer ones.\n",
      "---\n",
      "Zynthian allows the beats per bar to be configured but not the beat type. All beats are assumed to be quarter notes and the default beats per bar is 4, hence a 4/4 time signature. The beats per bar may be adjusted from a menu option and can be set to any value between 1 and 64. The most significant behaviour that beats per bar influences is the sync point. The sync point is the point at which a sequence starts, loops or stops and is synonymous with start of bar hence the beats per bar defines the quantity of beats between sync points which in turn defines the rate at which sequences will loop.\n",
      "---\n",
      "There is a pitch control that adjusts the pitch of the audio without changing its speed.\n",
      "---\n",
      "There is a speed control that adjusts the speed of the audio without changing its pitch.\n",
      "---\n",
      "NOTE: The MPK resolution is 1BPM, but Zynthian is 0.1BPM; take this into account to avoid drifting. \n",
      "---\n",
      "There are vertical white lines indicating the beats. The quantity of beats in the pattern may be adjusted from the menu as well as the quantity of steps in each beat. This allows the duration and quantisation level of the pattern to be adjusted. Changing the beats in pattern will change the pattern duration. Changing the steps per beat will change the pattern resolution.\n",
      "---\n",
      "ZynSeq uses JACK timebase for its timing. Transport control and adjustment of tempo may be made by external JACK clients. Those clients may also use the same timebase. This means that ZynSeq can synchronise with other modules within Zynthian, e.g. synth engine LFO, arpeggiators, etc. It also means that other modules may control ZynSeq playback to some degree. ZynSeq acts as the timebase master, i.e. the concept of bars, beats and ticks (fractions of beats) and consequently tempo (BPM) is provided by ZynSeq. There is currently no mechanism to lock to external MIDI clock but a Zynthian MIDI effects layer may be used to create MIDI clock output. There is a plan to improve this support in a future update.\n",
      "---\n",
      "You may wish to use one sequence as a click track by having a simple percusion sound looping. You could use a similar track in oneshot mode as the count-in for a song, pressing pads for the first bars of the song whilst the count-in playing or maybe use a silent sequence for the same purpose to allow manual synchronisation of several sequences at the start of a performance.\n",
      "---\n",
      "The current value of beats per bar is saved with the snapshot and restored when a snapshot is loaded. The beats per bar may also be varied during sequence playback and will be added to a sequence within the arranger. This functionality is currently disabled.\n",
      "---\n",
      "To preview a pattern, start or pause the transport by pressing the play button, learn/shot encoder or tapping the status area. A coloured bar at the bottom of the view will move left to right to indicate the position of the playhead and any notes entered in the pattern will be sent to the zynthian's engines. To stop and recue to the start of the pattern, bold press. Playback speed (Tempo) can be adjusted with the encoder 1 or by selecting \"Tempo\" from the menu.\n",
      "---\n",
      "MIDI learning\n",
      "---\n",
      "There is a control to adjust the beats in the sample. This may be used to synchronise the sample with sequencer playback. If the beats has been set to a non-zero value, the marker menu has an option to create that quantity of equally spaced cue markers.\n",
      "---\n",
      "MIDI triggered playback is affected by an AHDSR envelope with controls for:\n",
      "---\n",
      "The playback indication icon changes to red to indicate it is stopping and then disappears to indicate it has stopped. Most play modes will continue to play the sequence until the next sync point. A sync point may be thought of as the start or end of a bar, indeed their spacing is set using the menu option Beats per bar.\n",
      "---\n",
      "A pattern may be exported as a standard MIDI file. The tempo and all the notes within the pattern on its current channel will be exported to a file in Zynthian's capture location which may be accessed via webconf. The filename will consist of the pattern number and a date / time stamp of when the export occured, e.g. pattern2_2021-02-18 15:15:19.335558.mid.\n",
      "---\n",
      "There is a varispeed control that adjusts both speed and pitch, like varying the speed of a tape machine. This can also be used like a scrub control, allowing both forward and reverse playback.\n",
      "---\n",
      "Each note may be adjusted to have different duration, velocity, etc. To adjust a note's parameters, bold SELECT to show the parameter editor. Use encoder 4 (or onscreen buttons if enabled) to select the parameter to adjust. The options are:\n",
      "---\n",
      "PatternA pattern contiains zero or more events. Each pattern has a duration in steps and may include as many simultaneous (polyphonic) notes as desired on each step. We will see how patterns are manipulated in the  Pattern Editor section\n",
      "---\n",
      "Within the scrollbar is an infomation display. By default this shows the duration of the sample. There is a control to adjust the displayed info:\n",
      "---\n",
      "A Sync point is a location within playback at which sequences will loop and / or group sequential play will change to another sequence. Sync points are synonymous with bars in traditional music notation. See section on time signature.\n",
      "---\n",
      "There is a grid on the right called the Step Grid. On the left is a representation of a piano keyboard, scale or drum map. Each row represents a note and each column in the step grid represents a step in the sequence.\n",
      "---\n",
      "As you can see in the image, this mode mimics the Zynthian V5 hardware interface. The upper four buttons are OPT/ADMIN, MIX/LEVEL, CTRL/PRESET and ZS3/SHOT. Next row is ALT, METRONOME and PAD/STEP. The four buttons at the right side (in white) are F1 to F4. In this mode, transport is handled by PLAY/PAUSE and RECORD buttons, and the transport pads are only to show playback/recording status. Navigation buttons are UP, DOWN, LEFT, RIGHT, (in yellow) BACK/NO (in red) and SEL/YES (in green). For the directional keys, you can also use the track keys labelled as such. \n",
      "---\n",
      "Question:\n",
      "What is known about tempo?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_prompt(question, \n",
    "                context_df,\n",
    "                embedding_model_name,\n",
    "                max_question_len=100, \n",
    "                max_prompt_tokens=1800,\n",
    "                verbose=False):\n",
    "    \"\"\"\n",
    "    This function provides standardized prompts. The context is ordered by relevance to the user query.\n",
    "    \n",
    "    Args:\n",
    "        question: the string that is used to order the dataset by likeliness\n",
    "        context_df: the unordered DataFrame with \"text\" and \"embeddings\" columns\n",
    "        embedding_model_name: in what manner OpenAI should encode the data\n",
    "        max_question_len: the number of characters shouldn't exceed this number\n",
    "        max_prompt_tokens: not more than this number of tokens will be passed to OpenAI and exiting\n",
    "            early the context creation if this value is exceeded\n",
    "    Returns:\n",
    "        str: the prompt with relevant context and user question\n",
    "    \n",
    "    \"\"\"\n",
    "    assert len(question) < max_question_len, f\"Your question is too long, please rephrase to use less than {max_question_len} charachters.\"\n",
    "    if verbose:\n",
    "        print(f\"[info] Making a prompt for: {question}\")\n",
    "    # set up raw layout of prompt\n",
    "    prompt_context = \"Context:\\n\"\n",
    "    prompt_question = f\"Question:\\n{question}\"\n",
    "    relevant_context = get_relevant_context(question, context_df, embedding_model_name)\n",
    "    \n",
    "    # begin assembling the relevant context as long as there are unused tokens left\n",
    "    remaining_tokens = len(tokenizer.encode(prompt_context)) + len(tokenizer.encode(prompt_question))\n",
    "    for idx, text_element in enumerate(relevant_context[\"text\"]):\n",
    "        remaining_tokens += len(tokenizer.encode(text_element))\n",
    "        if remaining_tokens > max_prompt_tokens:\n",
    "            if verbose:\n",
    "                print(f\"[info] Limited context to {idx}/{relevant_context.shape[0]} paragraphs\")\n",
    "            break\n",
    "        else:\n",
    "            prompt_context += f\"{text_element}\\n---\\n\"\n",
    "    \n",
    "    # complete full prompt\n",
    "    prompt = prompt_context + prompt_question\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"[info] Created following prompt:\")\n",
    "        print(f\"===========================\\n\\n{prompt}\\n\\n\")\n",
    "\n",
    "    return prompt\n",
    "\n",
    "_ = make_prompt(test_question, context_with_embeddings_df, embedding_model_name, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef03994d",
   "metadata": {},
   "source": [
    "### Prompt submission\n",
    "After all preparations have been made to provide a prompt of higher quality, a standardized way of querying OpenAI's model with that prompt is established first before eventually running a test comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_openai(prompt:str, completion_model_name:str, max_answer_tokens:int=200) -> str:\n",
    "    \"\"\"\n",
    "    This submits arbitrary prompts to OpenAI's Completion interface and \n",
    "    returns the most likely estimate as a string\n",
    "    \n",
    "    Args:\n",
    "        prompt: the query that will be passed to the model\n",
    "        completion_model_name: the model that the query should interfere with\n",
    "        max_answer_tokens: limitation to avoid overstraining OpenAI services\n",
    "    Returns:\n",
    "        str: the most likely answer for the input question    \n",
    "    \"\"\"  \n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=completion_model_name,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        # return most likely answer\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    # Embedding this in a sand box if for instance the API is not reachable.\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "Here the performance is demonstrated by two questions:\n",
    "\n",
    "- the vanilla modus just takes the question and queries OpenAI's Completion model.\n",
    "- the context modus takes the question and adds, relative to the given question, relevant information from the Zynthian user guides.\n",
    "\n",
    "Two questions are being picked that are less likely to be answered by general knowledge of synthesizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "This question covers a couple of paragraphs referencing the unit, that makes guessing harder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f0736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"List all functions of the 'short-push' button in Zynthian.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4901c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Selecting a menu option: The short-push button can be used to select a menu option on the Zynthian display. This is useful for navigating through different menus and sub-menus.\n",
      "\n",
      "2. Confirming a selection: Once a menu option has been selected, the short-push button can be used to confirm the selection and execute the command associated with it.\n",
      "\n",
      "3. Scrolling through lists: In certain menus or sub-menus, the short-push button can be used to scroll through a list of options. This is typically used when there are more options than can fit on the display at once.\n",
      "\n",
      "4. Muting/unmuting a layer: When playing a synthesizer or sampler layer, the short-push button can be used to mute or unmute that layer. This is useful for creating variations in a performance or for soloing a specific layer.\n",
      "\n",
      "5. Setting the tempo: Pressing and holding the short-push button for a few seconds will allow you to adjust the tempo of\n"
     ]
    }
   ],
   "source": [
    "vanilla_prompt = question\n",
    "print(ask_openai(vanilla_prompt, completion_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Access the zynthian's classic workflow (V1-V4).\n",
      "2. Contextual global actions.\n",
      "3. Show onscreen buttons.\n",
      "4. View basic configuration information on the dashboard.\n",
      "5. Control the Zynthian UI using Shift+Device.\n",
      "6. Blink the device button in red when the mode is active.\n",
      "7. Redefine the functionality of transport, arrows, and F1-F4 buttons.\n",
      "8. Mimic the Zynthian V5 hardware interface.\n",
      "9. Enable transport buttons for playback/recording status.\n",
      "10. Use the UP, DOWN, LEFT, RIGHT, BACK/NO, and SEL/YES buttons for navigation.\n",
      "11. Use track keys as directional keys.\n",
      "12. Use a MIDI keyboard to trigger a sequence.\n",
      "13. Configure Zynthian interface options in webconf.\n",
      "14. Update the Zynthian software.\n",
      "15. Preview a pattern and adjust tempo with the encoder or menu.\n",
      "16. Use the nearest four knobs as Knob\n"
     ]
    }
   ],
   "source": [
    "context_prompt = make_prompt(question, context_with_embeddings_df, embedding_model_name)\n",
    "print(ask_openai(context_prompt, completion_model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "For verification see https://wiki.zynthian.org/index.php/ZynSeq_User_Guide#Time_Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f646989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most significant behavior that influences beats per bar in Zynthian is the tempo setting. This determines the speed at which the beats per bar are played. Other factors such as the time signature and the type of rhythm or pattern being used can also affect the beats per bar, but the tempo is the main factor that determines the overall speed of the beats.\n"
     ]
    }
   ],
   "source": [
    "question = \"In Zynthian: what is the most significant behaviour that influences beats per bar ?\"\n",
    "vanilla_prompt = question\n",
    "print(ask_openai(vanilla_prompt, completion_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The sync point.\n"
     ]
    }
   ],
   "source": [
    "context_prompt = make_prompt(question, context_with_embeddings_df, embedding_model_name)\n",
    "print(ask_openai(context_prompt, completion_model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
